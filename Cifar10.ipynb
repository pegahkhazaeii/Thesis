{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cifar10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoAnK7wL8QbL",
        "outputId": "8c042769-198f-4b1e-be19-d6ee04015efb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spikingjelly\n",
            "  Downloading spikingjelly-0.0.0.0.8-py3-none-any.whl (213 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▌                              | 10 kB 30.6 MB/s eta 0:00:01\r\u001b[K     |███                             | 20 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 30 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 40 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 51 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 61 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 71 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 81 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 92 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 102 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 112 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 122 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 133 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 143 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 153 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 163 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 174 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 184 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 194 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 204 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 213 kB 8.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from spikingjelly) (1.10.0+cu111)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from spikingjelly) (4.62.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from spikingjelly) (3.2.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from spikingjelly) (0.11.1+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from spikingjelly) (1.21.5)\n",
            "Collecting onnx==1.8.0\n",
            "  Downloading onnx-1.8.0-cp37-cp37m-manylinux2010_x86_64.whl (7.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.7 MB 27.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from spikingjelly) (1.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.0->spikingjelly) (3.10.0.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.0->spikingjelly) (3.17.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.0->spikingjelly) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->spikingjelly) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->spikingjelly) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->spikingjelly) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->spikingjelly) (3.0.7)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->spikingjelly) (7.1.2)\n",
            "Installing collected packages: onnx, spikingjelly\n",
            "Successfully installed onnx-1.8.0 spikingjelly-0.0.0.0.8\n"
          ]
        }
      ],
      "source": [
        "pip install spikingjelly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.argv=['']\n",
        "del sys"
      ],
      "metadata": {
        "id": "Ol3lb4Vl8dt-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from spikingjelly.clock_driven import neuron, functional, surrogate, layer\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import os\n",
        "import time\n",
        "import argparse\n",
        "import numpy as np\n",
        "from torch.cuda import amp\n",
        "_seed_ = 2020\n",
        "torch.manual_seed(_seed_)  \n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(_seed_)\n",
        "\n",
        "class PythonNet(nn.Module):\n",
        "    def __init__(self, T):\n",
        "        super().__init__()\n",
        "        self.T = T\n",
        "\n",
        "        self.static_conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "\n",
        "        )\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            neuron.IFNode(surrogate_function=surrogate.Sigmoid()),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 64, 3, 1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            neuron.IFNode(surrogate_function=surrogate.Sigmoid()),\n",
        "            nn.Conv2d(64, 128, 3, 1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            neuron.IFNode(surrogate_function=surrogate.Sigmoid()),\n",
        "            nn.MaxPool2d(2, 2), \n",
        "            nn.Conv2d(128, 128, 3, 1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            neuron.IFNode(surrogate_function=surrogate.Sigmoid()),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(128, 256, 3, 1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2*2*256, 1024),\n",
        "            neuron.IFNode(surrogate_function=surrogate.Sigmoid()),\n",
        "            nn.Linear(1024, 512),\n",
        "            neuron.IFNode(surrogate_function=surrogate.Sigmoid()),\n",
        "            nn.Linear(512, 10),\n",
        "            neuron.IFNode(surrogate_function=surrogate.Sigmoid()),\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.static_conv(x)\n",
        "\n",
        "        out_spikes_counter = self.fc(self.conv(x))\n",
        "        for t in range(1, self.T):\n",
        "            out_spikes_counter += self.fc(self.conv(x))\n",
        "\n",
        "        return out_spikes_counter / self.T\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "\n",
        "    parser = argparse.ArgumentParser(description='Classify-Cifar10')\n",
        "    parser.add_argument('-T', default=6, type=int, help='simulating time-steps')\n",
        "    parser.add_argument('-device', default='cuda:0', help='device')\n",
        "    parser.add_argument('-b', default=64, type=int, help='batch size')\n",
        "    parser.add_argument('-epochs', default=60, type=int, metavar='N',\n",
        "                        help='number of total epochs to run')\n",
        "    parser.add_argument('-j', default=4, type=int, metavar='N',\n",
        "                        help='number of data loading workers (default: 4)')\n",
        "    parser.add_argument('-data_dir', type=str, help='root dir of Cifar10 dataset')\n",
        "    parser.add_argument('-out_dir', type=str, default='./logs', help='root dir for saving logs and checkpoint')\n",
        "\n",
        "    parser.add_argument('-resume', type=str, help='resume from the checkfpoint path')\n",
        "    parser.add_argument('-amp', action='store_true', help='automatic mixed precision training')\n",
        "    parser.add_argument('-cupy', action='store_true', help='use cupy neuron and multi-step forward mode')\n",
        "\n",
        "    parser.add_argument('-opt', default='Adam',type=str)\n",
        "    parser.add_argument('-lr', default=0.001, type=float, help='learning rate')\n",
        "    parser.add_argument('-momentum', default=0.9, type=float, help='momentum for SGD')\n",
        "    parser.add_argument('-lr_scheduler', default='CosALR', type=str, help='use which schedule. StepLR or CosALR')\n",
        "    parser.add_argument('-step_size', default=32, type=float, help='step_size for StepLR')\n",
        "    parser.add_argument('-gamma', default=0.1, type=float, help='gamma for StepLR')\n",
        "    parser.add_argument('-T_max', default=64, type=int, help='T_max for CosineAnnealingLR')\n",
        "    args = parser.parse_args()\n",
        "    print(args)\n",
        "\n",
        "    net = PythonNet(T=args.T)\n",
        "    print(net)\n",
        "    net.to(args.device)\n",
        "\n",
        "    optimizer = None\n",
        "    if args.opt == 'SGD':\n",
        "        optimizer = torch.optim.SGD(net.parameters(), lr=args.lr, momentum=args.momentum)\n",
        "    elif args.opt == 'Adam':\n",
        "        optimizer = torch.optim.Adam(net.parameters(), lr=args.lr)\n",
        "    else:\n",
        "        raise NotImplementedError(args.opt)\n",
        "\n",
        "    lr_scheduler = None\n",
        "    if args.lr_scheduler == 'StepLR':\n",
        "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)\n",
        "    elif args.lr_scheduler == 'CosALR':\n",
        "        lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.T_max)\n",
        "    else:\n",
        "        raise NotImplementedError(args.lr_scheduler)\n",
        "\n",
        "\n",
        "    train_set = torchvision.datasets.CIFAR10(\n",
        "            root='./',\n",
        "            train=True,\n",
        "             transform= transforms.Compose([ \n",
        "            transforms.RandomHorizontalFlip(), \n",
        "            transforms.RandomRotation((-7,7)),     \n",
        "            transforms.RandomAffine(0, shear=10, scale=(0.8,1.2)), \n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.491, 0.482, 0.446), (0.247, 0.243, 0.261)) \n",
        "            ]),\n",
        "             download=True)\n",
        "\n",
        "    test_set = torchvision.datasets.CIFAR10(\n",
        "            root='./',\n",
        "            train=False,\n",
        "            transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.491, 0.482, 0.446), (0.247, 0.243, 0.261))\n",
        "        ]),\n",
        "            download=True)\n",
        "\n",
        "    train_data_loader = torch.utils.data.DataLoader(\n",
        "        dataset=train_set,\n",
        "        batch_size=args.b,\n",
        "        shuffle=True,\n",
        "        drop_last=False,\n",
        "        num_workers=args.j\n",
        "    )\n",
        "\n",
        "    test_data_loader = torch.utils.data.DataLoader(\n",
        "        dataset=test_set,\n",
        "        batch_size=args.b,\n",
        "        shuffle=True,\n",
        "        drop_last=False,\n",
        "        num_workers=args.j\n",
        "    )\n",
        "\n",
        "    scaler = None\n",
        "    if args.amp:\n",
        "        scaler = amp.GradScaler()\n",
        "\n",
        "    start_epoch = 0\n",
        "    max_test_acc = 0\n",
        "\n",
        "    if args.resume:\n",
        "        checkpoint = torch.load(args.resume, map_location='cpu')\n",
        "        net.load_state_dict(checkpoint['net'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        max_test_acc = checkpoint['max_test_acc']\n",
        "\n",
        "    out_dir = os.path.join(args.out_dir, f'T_{args.T}_b_{args.b}_{args.opt}_lr_{args.lr}_')\n",
        "\n",
        "    writer = SummaryWriter(os.path.join(out_dir, 'fmnist_logs'), purge_step=start_epoch)\n",
        "\n",
        "    for epoch in range(start_epoch, args.epochs):\n",
        "        start_time = time.time()\n",
        "        net.train()\n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "        train_samples = 0\n",
        "        for frame, label in train_data_loader:\n",
        "            optimizer.zero_grad()\n",
        "            frame = frame.float().to(args.device)\n",
        "            label = label.to(args.device)\n",
        "            label_onehot = F.one_hot(label, 10).float()\n",
        "            if args.amp:\n",
        "                with amp.autocast():\n",
        "                    out_fr = net(frame)\n",
        "                    loss = F.mse_loss(out_fr, label_onehot)\n",
        "                scaler.scale(loss).backward()\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "            else:\n",
        "                out_fr = net(frame)\n",
        "                loss = F.mse_loss(out_fr, label_onehot)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            train_samples += label.numel()\n",
        "            train_loss += loss.item() * label.numel()\n",
        "            train_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
        "\n",
        "            functional.reset_net(net)\n",
        "        train_loss /= train_samples\n",
        "        train_acc /= train_samples\n",
        "\n",
        "        writer.add_scalar('train_loss', train_loss, epoch)\n",
        "        writer.add_scalar('train_acc', train_acc, epoch)\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        net.eval()\n",
        "        test_loss = 0\n",
        "        test_acc = 0\n",
        "        test_samples = 0\n",
        "        with torch.no_grad():\n",
        "            for frame, label in test_data_loader:\n",
        "                frame = frame.float().to(args.device)\n",
        "                label = label.to(args.device)\n",
        "                label_onehot = F.one_hot(label, 10).float()\n",
        "                out_fr = net(frame)\n",
        "                loss = F.mse_loss(out_fr, label_onehot)\n",
        "\n",
        "                test_samples += label.numel()\n",
        "                test_loss += loss.item() * label.numel()\n",
        "                test_acc += (out_fr.argmax(1) == label).float().sum().item()\n",
        "                functional.reset_net(net)\n",
        "\n",
        "        test_loss /= test_samples\n",
        "        test_acc /= test_samples\n",
        "        writer.add_scalar('test_loss', test_loss, epoch)\n",
        "        writer.add_scalar('test_acc', test_acc, epoch)\n",
        "\n",
        "        save_max = False\n",
        "        if test_acc > max_test_acc:\n",
        "            max_test_acc = test_acc\n",
        "            save_max = True\n",
        "\n",
        "        checkpoint = {\n",
        "            'net': net.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'lr_scheduler': lr_scheduler.state_dict(),\n",
        "            'epoch': epoch,\n",
        "            'max_test_acc': max_test_acc\n",
        "        }\n",
        "\n",
        "        if save_max:\n",
        "            torch.save(checkpoint, os.path.join(out_dir, 'checkpoint_max.pth'))\n",
        "\n",
        "        torch.save(checkpoint, os.path.join(out_dir, 'checkpoint_latest.pth'))\n",
        "\n",
        "        print(args)\n",
        "        print(out_dir)\n",
        "        print(\n",
        "            f'epoch={epoch}, train_loss={train_loss}, train_acc={train_acc}, test_loss={test_loss}, test_acc={test_acc}, max_test_acc={max_test_acc}, total_time={time.time() - start_time}')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vb3T4u5-8d0S",
        "outputId": "85886795-b173-4684-806c-314c48eede83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "PythonNet(\n",
            "  (static_conv): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv): Sequential(\n",
            "    (0): IFNode(\n",
            "      v_threshold=1.0, v_reset=0.0, detach_reset=False\n",
            "      (surrogate_function): Sigmoid(alpha=1.0, spiking=True)\n",
            "    )\n",
            "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): IFNode(\n",
            "      v_threshold=1.0, v_reset=0.0, detach_reset=False\n",
            "      (surrogate_function): Sigmoid(alpha=1.0, spiking=True)\n",
            "    )\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): IFNode(\n",
            "      v_threshold=1.0, v_reset=0.0, detach_reset=False\n",
            "      (surrogate_function): Sigmoid(alpha=1.0, spiking=True)\n",
            "    )\n",
            "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): IFNode(\n",
            "      v_threshold=1.0, v_reset=0.0, detach_reset=False\n",
            "      (surrogate_function): Sigmoid(alpha=1.0, spiking=True)\n",
            "    )\n",
            "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (2): IFNode(\n",
            "      v_threshold=1.0, v_reset=0.0, detach_reset=False\n",
            "      (surrogate_function): Sigmoid(alpha=1.0, spiking=True)\n",
            "    )\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): IFNode(\n",
            "      v_threshold=1.0, v_reset=0.0, detach_reset=False\n",
            "      (surrogate_function): Sigmoid(alpha=1.0, spiking=True)\n",
            "    )\n",
            "    (5): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=0, train_loss=0.07128866037368774, train_acc=0.43244, test_loss=0.06367138518691062, test_acc=0.5098, max_test_acc=0.5098, total_time=91.31381821632385\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=1, train_loss=0.05676096290349961, train_acc=0.57528, test_loss=0.0497848535656929, test_acc=0.6317, max_test_acc=0.6317, total_time=91.53213334083557\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=2, train_loss=0.049861147207021714, train_acc=0.63366, test_loss=0.04483814800381661, test_acc=0.6764, max_test_acc=0.6764, total_time=91.23681807518005\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=3, train_loss=0.045910921573638915, train_acc=0.66622, test_loss=0.0419874585211277, test_acc=0.6993, max_test_acc=0.6993, total_time=91.49690747261047\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=4, train_loss=0.04281526448845863, train_acc=0.69374, test_loss=0.03982159477472305, test_acc=0.7164, max_test_acc=0.7164, total_time=91.66669273376465\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=5, train_loss=0.04083845028817654, train_acc=0.70706, test_loss=0.03974535564482212, test_acc=0.7135, max_test_acc=0.7164, total_time=91.35435056686401\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=6, train_loss=0.03916677221179009, train_acc=0.7203, test_loss=0.036891412764787676, test_acc=0.7376, max_test_acc=0.7376, total_time=91.048086643219\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=7, train_loss=0.03710821729660034, train_acc=0.73798, test_loss=0.035218822464346884, test_acc=0.7526, max_test_acc=0.7526, total_time=91.02581810951233\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=8, train_loss=0.03565603645205498, train_acc=0.74942, test_loss=0.034306870740652085, test_acc=0.7612, max_test_acc=0.7612, total_time=91.51153898239136\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=9, train_loss=0.03433263721585274, train_acc=0.75856, test_loss=0.032021462425589564, test_acc=0.7786, max_test_acc=0.7786, total_time=91.62970471382141\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=10, train_loss=0.03318146973371506, train_acc=0.76896, test_loss=0.03138274336755276, test_acc=0.7869, max_test_acc=0.7869, total_time=91.5457820892334\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=11, train_loss=0.03219004828095436, train_acc=0.77706, test_loss=0.030284642946720123, test_acc=0.7931, max_test_acc=0.7931, total_time=91.56000256538391\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=12, train_loss=0.031392236585617066, train_acc=0.7826, test_loss=0.0317432356774807, test_acc=0.784, max_test_acc=0.7931, total_time=91.1125500202179\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=13, train_loss=0.03046571616053581, train_acc=0.78868, test_loss=0.030481343948841094, test_acc=0.7899, max_test_acc=0.7931, total_time=91.45455169677734\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=14, train_loss=0.029543912566900254, train_acc=0.79662, test_loss=0.029474122869968415, test_acc=0.7981, max_test_acc=0.7981, total_time=91.40072703361511\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=15, train_loss=0.028619643035531044, train_acc=0.80224, test_loss=0.029048160189390184, test_acc=0.8029, max_test_acc=0.8029, total_time=91.60635089874268\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=16, train_loss=0.02804231717824936, train_acc=0.8078, test_loss=0.026915662735700608, test_acc=0.8184, max_test_acc=0.8184, total_time=91.5151584148407\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=17, train_loss=0.02697141474366188, train_acc=0.81662, test_loss=0.028012153339385986, test_acc=0.81, max_test_acc=0.8184, total_time=91.37280321121216\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=18, train_loss=0.026363548049926758, train_acc=0.82204, test_loss=0.026823907780647277, test_acc=0.8183, max_test_acc=0.8184, total_time=91.29814982414246\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=19, train_loss=0.025878501903414727, train_acc=0.82604, test_loss=0.026834807133674622, test_acc=0.8199, max_test_acc=0.8199, total_time=91.5009331703186\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=20, train_loss=0.025054309567809106, train_acc=0.83078, test_loss=0.026868619412183763, test_acc=0.821, max_test_acc=0.821, total_time=91.76941418647766\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=21, train_loss=0.024660508300065994, train_acc=0.835, test_loss=0.02680321230888367, test_acc=0.8227, max_test_acc=0.8227, total_time=91.88690090179443\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=22, train_loss=0.02405901511788368, train_acc=0.83954, test_loss=0.02637256342172623, test_acc=0.8215, max_test_acc=0.8227, total_time=91.39625883102417\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=23, train_loss=0.023490608963668346, train_acc=0.84192, test_loss=0.025647281563282012, test_acc=0.8288, max_test_acc=0.8288, total_time=91.9393241405487\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=24, train_loss=0.02277766466021538, train_acc=0.84798, test_loss=0.02537336600422859, test_acc=0.8309, max_test_acc=0.8309, total_time=91.31908750534058\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=25, train_loss=0.022336713519096375, train_acc=0.8508, test_loss=0.024707270032167435, test_acc=0.8332, max_test_acc=0.8332, total_time=91.78743600845337\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=26, train_loss=0.02178362039923668, train_acc=0.85634, test_loss=0.024511647510528565, test_acc=0.8363, max_test_acc=0.8363, total_time=91.65588784217834\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=27, train_loss=0.021357976072728633, train_acc=0.86086, test_loss=0.024293260511755944, test_acc=0.8407, max_test_acc=0.8407, total_time=91.84432554244995\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=28, train_loss=0.020827104416489602, train_acc=0.86338, test_loss=0.024474777142703533, test_acc=0.8381, max_test_acc=0.8407, total_time=91.842538356781\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=29, train_loss=0.020179589933753014, train_acc=0.86704, test_loss=0.023800388711690903, test_acc=0.8448, max_test_acc=0.8448, total_time=91.45611047744751\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=30, train_loss=0.019606955394744875, train_acc=0.8714, test_loss=0.024710833658650518, test_acc=0.8371, max_test_acc=0.8448, total_time=91.62606120109558\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=31, train_loss=0.01911907217502594, train_acc=0.87656, test_loss=0.024157625219225883, test_acc=0.8433, max_test_acc=0.8448, total_time=91.62552547454834\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=32, train_loss=0.018540201100707053, train_acc=0.88, test_loss=0.024346518006920816, test_acc=0.842, max_test_acc=0.8448, total_time=91.5096230506897\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=33, train_loss=0.018286874081790448, train_acc=0.88068, test_loss=0.023711830839514732, test_acc=0.8464, max_test_acc=0.8464, total_time=91.92894411087036\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=34, train_loss=0.017821981591582298, train_acc=0.88472, test_loss=0.023362695243954658, test_acc=0.8514, max_test_acc=0.8514, total_time=91.61414504051208\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=35, train_loss=0.01744906409740448, train_acc=0.8878, test_loss=0.024014347660541533, test_acc=0.8441, max_test_acc=0.8514, total_time=92.09232115745544\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=36, train_loss=0.017111540837883948, train_acc=0.8913, test_loss=0.02318734656572342, test_acc=0.8478, max_test_acc=0.8514, total_time=92.155268907547\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=37, train_loss=0.016643158650994302, train_acc=0.89336, test_loss=0.023118651968240738, test_acc=0.8513, max_test_acc=0.8514, total_time=91.6409969329834\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=38, train_loss=0.01632313428223133, train_acc=0.8966, test_loss=0.0234931482732296, test_acc=0.8461, max_test_acc=0.8514, total_time=91.91444420814514\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=39, train_loss=0.015698662259280682, train_acc=0.89998, test_loss=0.02296697109043598, test_acc=0.8534, max_test_acc=0.8534, total_time=91.64455938339233\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=40, train_loss=0.015384486264288426, train_acc=0.90284, test_loss=0.02346793999373913, test_acc=0.8504, max_test_acc=0.8534, total_time=91.82550883293152\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=41, train_loss=0.01519196656614542, train_acc=0.90466, test_loss=0.02340270298421383, test_acc=0.8486, max_test_acc=0.8534, total_time=91.58823943138123\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=42, train_loss=0.014739987154901027, train_acc=0.90796, test_loss=0.023583975225687028, test_acc=0.8486, max_test_acc=0.8534, total_time=91.72269630432129\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=43, train_loss=0.014397006586492062, train_acc=0.9106, test_loss=0.023752036449313164, test_acc=0.8486, max_test_acc=0.8534, total_time=91.78154063224792\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=44, train_loss=0.014097907013595104, train_acc=0.91314, test_loss=0.02294725199341774, test_acc=0.8514, max_test_acc=0.8534, total_time=91.53936219215393\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=45, train_loss=0.013780747543126345, train_acc=0.91586, test_loss=0.022496336007118225, test_acc=0.8542, max_test_acc=0.8542, total_time=91.68642497062683\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=46, train_loss=0.013394257829487324, train_acc=0.91822, test_loss=0.022443805262446402, test_acc=0.8578, max_test_acc=0.8578, total_time=91.3857307434082\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=47, train_loss=0.013070952226743102, train_acc=0.92052, test_loss=0.022844790223240853, test_acc=0.8539, max_test_acc=0.8578, total_time=91.76779508590698\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=48, train_loss=0.013105220257341862, train_acc=0.91924, test_loss=0.02294490071237087, test_acc=0.8545, max_test_acc=0.8578, total_time=91.90708827972412\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=49, train_loss=0.012748196469545364, train_acc=0.92228, test_loss=0.022529574766755104, test_acc=0.8559, max_test_acc=0.8578, total_time=91.92561149597168\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=50, train_loss=0.012753077019155026, train_acc=0.9225, test_loss=0.022550744524598123, test_acc=0.8557, max_test_acc=0.8578, total_time=91.82987928390503\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=51, train_loss=0.01232918177843094, train_acc=0.92548, test_loss=0.02246909778416157, test_acc=0.861, max_test_acc=0.861, total_time=91.73569059371948\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=52, train_loss=0.012300881833732128, train_acc=0.92642, test_loss=0.022503305950760843, test_acc=0.8552, max_test_acc=0.861, total_time=91.61921119689941\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=53, train_loss=0.012258606390058994, train_acc=0.92638, test_loss=0.022695414241030814, test_acc=0.8553, max_test_acc=0.861, total_time=91.72765040397644\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=54, train_loss=0.011735080457180738, train_acc=0.93128, test_loss=0.022280969420075417, test_acc=0.8613, max_test_acc=0.8613, total_time=91.51341009140015\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=55, train_loss=0.01177396839722991, train_acc=0.92964, test_loss=0.022234165272116663, test_acc=0.8597, max_test_acc=0.8613, total_time=91.8559033870697\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=56, train_loss=0.011856310485303402, train_acc=0.92918, test_loss=0.022211186066269876, test_acc=0.8586, max_test_acc=0.8613, total_time=92.32693910598755\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=57, train_loss=0.011804894971847535, train_acc=0.92966, test_loss=0.022457852548360826, test_acc=0.8561, max_test_acc=0.8613, total_time=91.98174476623535\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=58, train_loss=0.011644325967133046, train_acc=0.9303, test_loss=0.022233795680105688, test_acc=0.8596, max_test_acc=0.8613, total_time=91.81363463401794\n",
            "Namespace(T=6, T_max=64, amp=False, b=64, cupy=False, data_dir=None, device='cuda:0', epochs=60, gamma=0.1, j=4, lr=0.001, lr_scheduler='CosALR', momentum=0.9, opt='Adam', out_dir='./logs', resume=None, step_size=32)\n",
            "./logs/T_6_b_64_Adam_lr_0.001_\n",
            "epoch=59, train_loss=0.011616560405492783, train_acc=0.93056, test_loss=0.02203406347632408, test_acc=0.8611, max_test_acc=0.8613, total_time=91.2245523929596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fehBOZy38d4Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}